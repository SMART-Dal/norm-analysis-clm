{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc6fdb16-1ee1-425f-b16d-a62a4e92e205",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys  \n",
    "sys.path.insert(0, './utils')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "178868ca-0acb-4ea5-891e-436856e9c948",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import json, os\n",
    "from tqdm import tqdm\n",
    "import queue\n",
    "import code_tokenize as ctok\n",
    "import math\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ee29be-9a32-4d82-b931-c911f85acd7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_consecutive_repeated_ranges(lst):\n",
    "    grouped_ranges = []\n",
    "    \n",
    "    if len(lst) == 0:\n",
    "        return grouped_ranges\n",
    "    \n",
    "    begin = 0\n",
    "    \n",
    "    for i in range(1, len(lst)):\n",
    "        if lst[i] != lst[i - 1]:\n",
    "            grouped_ranges.append((begin, i - 1))\n",
    "            begin = i\n",
    "    \n",
    "    grouped_ranges.append((begin, len(lst) - 1))  # Append the last range\n",
    "    \n",
    "    return grouped_ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd83912f-8fc3-45e4-b7cb-027abddbdfc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_tokens_to_hf_idx(code_tokens):\n",
    "    hf_tokens = hf_tokenizer.tokenize(' '.join(code_tokens))\n",
    "    enc_plus = hf_tokenizer.encode_plus(' '.join(code_tokens))\n",
    "    sub_tokenized_ids = enc_plus.word_ids()[1:-1] # First position and last positions are None since we don't apped [CLS] and [SEP]\n",
    "    grouped = group_consecutive_repeated_ranges(sub_tokenized_ids)\n",
    "    hf_mapping = []\n",
    "    idx = 0 # Because we will add [CLS] later on at the beginning\n",
    "    for i, tok in enumerate(code_tokens):\n",
    "        l = grouped[i][0]\n",
    "        u = grouped[i][1]\n",
    "        _range = (u - l)+1\n",
    "        hf_idx = []\n",
    "        for _ in range(_range):\n",
    "            idx += 1\n",
    "            hf_idx.append(idx)\n",
    "        hf_mapping.append([tok, hf_idx])\n",
    "    # Ref: https://github.com/huggingface/tokenizers/issues/266\n",
    "    # With CodeBERT's tokenizer if a token with string quotes such \"foo bar\", it is not\n",
    "    # possbile to revert it's subtokenization. Hence we discard the sample if the detokenization process\n",
    "    # is failed.\n",
    "\n",
    "    # Doing assertions for sanity checks. \n",
    "    # The following lines iterates over the original set of tokens `code_tokens`\n",
    "    # and their corresponding set of huggingface tokens' IDs, and checks whether\n",
    "    # the detokenized string from these IDs matches the token from `code_tokens`\n",
    "    for i, tok in enumerate(code_tokens):\n",
    "        l_bound = hf_mapping[i][1][0]-1 # Again because of [CLS]\n",
    "        u_bound = hf_mapping[i][1][-1]\n",
    "        decoded_token = hf_tokenizer.convert_tokens_to_string(hf_tokens[l_bound: u_bound]).replace(' ','')\n",
    "        if decoded_token != tok:\n",
    "            return [], []\n",
    "    \n",
    "    return hf_mapping, hf_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ee84f55-69fc-409b-835d-efb3080212cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_jsonl(filename, data_list):\n",
    "    \"\"\"\n",
    "    Save a list of dictionaries as JSON Lines (JSONL) format.\n",
    "\n",
    "    Args:\n",
    "        filename (str): The name of the output JSONL file.\n",
    "        data_list (list): List of dictionaries to be saved.\n",
    "    \"\"\"\n",
    "    with open(filename, 'w') as file:\n",
    "        for data_dict in data_list:\n",
    "            json.dump(data_dict, file)\n",
    "            file.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "efea103c-aebe-49e5-95c8-08162260dfad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_jsonl(file_path, split=''):\n",
    "    content = []\n",
    "    with open(file_path, 'r') as jsonl_file:\n",
    "    # Read the lines of the file\n",
    "        lines = jsonl_file.readlines()\n",
    "    for line in lines:\n",
    "        # Parse the JSON object\n",
    "        json_data = json.loads(line)\n",
    "        content.append(json_data)\n",
    "        \n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3a27943-d778-4cbe-9444-90942cd997f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.join(\"..\", \"raw_data\", \"csn_java_65k.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d8d45a9-bf77-474a-8117-ad691810f085",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = read_jsonl(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f21c4c8c-91d3-461e-a87a-264cd529a8e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd27cdab-e396-4f8c-a9fc-d1c08ca192df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['repository_name', 'func_path_in_repository', 'func_name', 'whole_func_string', 'language', 'func_code_string', 'func_code_tokens', 'func_documentation_string', 'func_documentation_tokens', 'split_name', 'func_code_url'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "07dd5bf6-4062-4850-b28e-b0ff798a5dde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "public static void configureFiles(Iterable<File> files)\n",
      "\t{\n",
      "\t\tfor (File file : files)\n",
      "\t\t{\n",
      "\t\t\tif (file != null && file.exists() && file.canRead())\n",
      "\t\t\t{\n",
      "\t\t\t\tsetup(file);\n",
      "\t\t\t\treturn;\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\n",
      "\t\tSystem.out.println(\"(No suitable log config file found)\");\n",
      "\t}\n"
     ]
    }
   ],
   "source": [
    "print(data[3]['whole_func_string'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "756dbea1-a2e9-427d-a876-bbfda965c329",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Types of java tokens:\n",
    "# 1) Keywords\n",
    "# 2) Identifiers\n",
    "# 3) Literals\n",
    "# 4) Operators\n",
    "# 5) Separators\n",
    "keywords = ['abstract', 'assert', 'boolean', 'break', 'byte', 'case', 'catch', 'char', 'class', 'const', 'continue', 'default', 'do', 'double', 'else', 'enum', 'extends', 'final', 'finally', 'float', 'for', 'goto', 'if', 'implements', 'import', 'instanceof', 'int', 'interface', 'long', 'native', 'new', 'package', 'private', 'protected', 'public', 'return', 'short', 'static', 'strictfp', 'super', 'switch', 'synchronized', 'this', 'throw', 'throws', 'transient', 'try', 'void', 'volatile', 'while']\n",
    "operators = [\n",
    "# Arithmetic Operators\n",
    "'+', '-', '*', '/', '%',\n",
    "# Unary Operators \n",
    "'+', '-', '++', '--',\n",
    "# Assignment Operators\n",
    "'=', '+=', '-=', '*=', '/=', '%=', '<<=', '>>=', '>>>=', '&=', '^=', '|=',\n",
    "# Relational Operators\n",
    "'==', '!=', '>', '<', '>=', '<=',\n",
    "# Logical Operators\n",
    "'&&', '||', '!',\n",
    "# Bitwise Operators\n",
    "'&', '|', '^', '~', '<<', '>>', '>>>',\n",
    "# Ternary Operator\n",
    "'?', ':',\n",
    "# Other operators\n",
    "'.', '...', '::'\n",
    "]\n",
    "symbols = [\";\", ',', \"{\", \"}\", \"(\", \")\", \"[\", \"]\", \"'\", '\"', \"@\", \"->\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "76f807d5-d699-4e09-8b1f-26618ed4c211",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5624d9a3-f867-4f53-a89e-54437e1abcf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "diffs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7414720d-326e-4f6f-a16c-b21ff030d8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_wrapper(code):\n",
    "    # Using this so that ctok stops complaining\n",
    "    backslash_char = \"\\\\\"\n",
    "    return \"class Dummy {\\n\" + code + \"\\n}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a323c84d-d5ca-4cc4-af5d-e35dd12ab6c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|████████████████████████████████████████████████████████████████████████████████████████████████████ | 64420/65000 [03:09<00:00, 1033.25it/s]"
     ]
    }
   ],
   "source": [
    "for code in tqdm(data):\n",
    "    wrapped_code = class_wrapper(code['whole_func_string'])\n",
    "    ctok_tokens = []\n",
    "    try:\n",
    "        ctok_tokens = ctok.tokenize(wrapped_code, lang=\"java\")[3:-1]\n",
    "    except:\n",
    "        ctok_tokens = []\n",
    "    original_tokens = code['func_code_tokens']\n",
    "    diff = abs(len(ctok_tokens) - len(original_tokens))\n",
    "    if not len(ctok_tokens):\n",
    "        diffs.append(-1)\n",
    "    else:\n",
    "        diffs.append(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abae897-2991-4fdd-b8c3-b037fdc6e3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b5932f5b-4aee-487f-8297-8c781c48cee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, diff in enumerate(diffs):\n",
    "    if diff != 0:\n",
    "        idx.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "78417e69-0261-4927-b0d3-e277a08216ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5035"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2092f4b2-572f-4afe-9710-fb84be96f80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9d18a42f-bb2d-4579-a1be-873cf5484b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, data_sample in enumerate(data):\n",
    "    if i not in idx:\n",
    "        filtered_data.append(data_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4c07c500-5176-404e-a136-4f8964357f6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59965"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(filtered_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "35bb1e10-5243-4fa8-a119-f799274f5d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_diffs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8683ea2a-53f7-4d4e-9687-17e600688894",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|█████████████████████████████████████████████▎                                                       | 26903/59965 [00:25<00:29, 1114.30it/s]"
     ]
    }
   ],
   "source": [
    "for code in tqdm(filtered_data):\n",
    "    wrapped_code = class_wrapper(code['whole_func_string'])\n",
    "    ctok_tokens = []\n",
    "    try:\n",
    "        ctok_tokens = ctok.tokenize(wrapped_code, lang=\"java\")[3:-1]\n",
    "    except:\n",
    "        ctok_tokens = []\n",
    "    original_tokens = code['func_code_tokens']\n",
    "    diff = abs(len(ctok_tokens) - len(original_tokens))\n",
    "    if not len(ctok_tokens):\n",
    "        new_diffs.append(-1)\n",
    "    else:\n",
    "        new_diffs.append(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "734a4fe6-5f9d-447f-84ab-7586369fd1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_idx = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a5890565-05e1-4579-956f-4812376fa196",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, diff in enumerate(new_diffs):\n",
    "    if diff != 0:\n",
    "        new_idx.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1ef13586-369d-49a2-87aa-10e80ff3f0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(new_idx) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3d62e02f-af24-437d-8e97-5f9085988c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_with_no_comments = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bea06f19-15d4-4680-9c84-83545c8632c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 59965/59965 [00:59<00:00, 1004.10it/s]\n"
     ]
    }
   ],
   "source": [
    "# Discard code with comments\n",
    "for code in tqdm(filtered_data):\n",
    "    wrapped_code = class_wrapper(code['whole_func_string'])\n",
    "    ctok_tokens = ctok.tokenize(wrapped_code, lang=\"java\")[3:-1]\n",
    "    ctok_types = set([tok.type for tok in ctok_tokens])\n",
    "    if ('line_comment' in ctok_types) or ('block_comment' in ctok_types) or ('comment' in ctok_types):\n",
    "        continue\n",
    "    else:\n",
    "        samples_with_no_comments.append(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9ed421bb-5c14-4513-9b22-942a536c369b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46787"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(samples_with_no_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c16d8cb1-10f4-49ec-a5a5-97d6db9e05c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "type_to_id = {\n",
    "    'Keyword': -1,\n",
    "    'Operator': -2,\n",
    "    'SpecialSymbol': -3,\n",
    "    'Literal': -4,\n",
    "    'Identifier': -5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "20cf9ac2-475e-44a2-8a26-71e743bf1565",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_types = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d257b7a3-37b0-4416-ac8c-58aac985aaa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 46787/46787 [00:57<00:00, 817.95it/s]\n"
     ]
    }
   ],
   "source": [
    "for sample in tqdm(samples_with_no_comments):\n",
    "    wrapped_code = class_wrapper(sample['whole_func_string'])\n",
    "    ctok_tokens = ctok.tokenize(wrapped_code, lang=\"java\")[3:-1]\n",
    "    token2cat = []\n",
    "    cat_ids = []\n",
    "    for tok in ctok_tokens:\n",
    "        if tok.type in keywords:\n",
    "            token2cat.append([str(tok), \"Keyword\"])\n",
    "            cat_ids.append(-1)\n",
    "        if ('boolean_type' in tok.type) or ('void_type' in tok.type): # for boolean type (i.e boolean k = ...), void (i.e. private void ..)\n",
    "            token2cat.append([str(tok), \"Keyword\"])\n",
    "            cat_ids.append(-1)\n",
    "        if tok.type in operators:\n",
    "            token2cat.append([str(tok), \"Operator\"])\n",
    "            cat_ids.append(-2)\n",
    "        if tok.type in symbols:\n",
    "            token2cat.append([str(tok), \"SpecialSymbol\"])\n",
    "            cat_ids.append(-3)\n",
    "        if '_literal' in tok.type:\n",
    "            token2cat.append([str(tok), \"Literal\"])\n",
    "            cat_ids.append(-4)\n",
    "        if 'false' == tok.type:\n",
    "            token2cat.append([str(tok), \"Literal\"])\n",
    "            cat_ids.append(-4)\n",
    "        if 'true' == tok.type:\n",
    "            token2cat.append([str(tok), \"Literal\"])\n",
    "            cat_ids.append(-4)\n",
    "        if 'identifier' in tok.type:\n",
    "            token2cat.append([str(tok), \"Identifier\"])\n",
    "            cat_ids.append(-5)\n",
    "    sample[\"tokens\"] = token2cat\n",
    "    sample[\"cat_ids\"] = cat_ids\n",
    "    assert len(token2cat) == len(ctok_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3114f103-10d4-468b-b90e-5c106d1dc878",
   "metadata": {},
   "outputs": [],
   "source": [
    "detokenizable_samples = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17772d7d-7d7a-4656-add5-b5d5c4676043",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample in tqdm(samples_with_no_comments):\n",
    "    hf_mapping, hf_tokens = map_tokens_to_hf_idx(sample['func_code_tokens'])\n",
    "    if (not len(hf_mapping)) or (not len(hf_tokens)):\n",
    "        continue\n",
    "    else:\n",
    "        sample['hf_mapping'] = hf_mapping\n",
    "        sample['hf_tokens'] = hf_tokens\n",
    "        detokenizable_samples.append(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0da0789-4028-487d-8b78-386bd6f8782c",
   "metadata": {},
   "outputs": [],
   "source": [
    "under_512 = list(filter(lambda x: len(x['hf_tokens']) <= 512, detokenizable_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10562a17-31d9-4c91-8ef8-6a3d781d3f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "study_sample = random.sample(under_512, 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457384aa-82b5-4dbd-968d-a536d437c0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_jsonl(os.path.join(\"..\", \"data\", \"5k_csn_java.jsonl\"), study_sample)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
